{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re #regular expression matching for removing unwanted columns by name \n",
    "import natsort as ns #3rd party package for natural sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raw_data_cleanup(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Imports RNAseq .csv file and does basic clean up of \"FM40\" \n",
    "        -sorts FM40 timecourse sequence chronologically\n",
    "        -removes all QC data and non FM40 columns\n",
    "        -returns dataframe with locus tag set as index\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"{} was located in the directory\".format(filename))\n",
    "                \n",
    "#import the data\n",
    "        data0_raw = pd.read_csv(filename, sep = \"\\t\") \n",
    "        print(\"{} was imported into dataframe\".format(filename))\n",
    "        \n",
    "#removing all QC data\n",
    "        data1_noQC = data0_raw.select(lambda x: not re.search(\"QC\", x), axis = 1) \n",
    "        print(\"QC columns were removed from dataframe\")\n",
    "\n",
    "#removing all non FM40 data\n",
    "        data2_FM40only = data1_noQC.select(lambda x: re.search(\"FM40\", x), axis = 1)\n",
    "        print(\"All non FM40 data were removed from dataframe\")\n",
    "        \n",
    "#naturally sorting FM40 data by columns \n",
    "        cols = list(ns.natsorted(data2_FM40only.columns))\n",
    "        data3_sorted=data2_FM40only[cols]\n",
    "        print(\"All FM40 columns were sorted by timecourse sequence\")\n",
    "        \n",
    "#adding the descriptor columns back to FM40\n",
    "        qualitative = data0_raw.loc[:,\"locus_tag\":\"translation\"]\n",
    "        data4_sorted = pd.concat([qualitative, data3_sorted], axis = 1)\n",
    "\n",
    "#setting locus tag to be the index\n",
    "        data5_index = data4_sorted.set_index(\"locus_tag\")\n",
    "        \n",
    "    \n",
    "        print(\"Clean-up of raw data complete\")\n",
    "        return data5_index\n",
    "        \n",
    "    else:\n",
    "        print(\"{} does not exist in directory. Function was not complete.\".format(filename))\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating TPM counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TPM_counts(dataframe, \n",
    "              gene_start,\n",
    "              gene_stop,\n",
    "              columns):\n",
    "    \n",
    "    \"\"\"\n",
    "    TPM_counts(dataframe, gene_start, gene_stop, columns):\n",
    "\n",
    "    returns a dataframe with TPM instead of reads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    daraframe = dataframe object variable\n",
    "    gene_start = string with column name containing gene start coordinate\n",
    "    gene_stop = string with column name containing gene stop coordinate\n",
    "    columns = list of strings of column names to be converted to TPM\n",
    "\n",
    "\n",
    "    Run the following two lines to properly execute this function:\n",
    "\n",
    "    columns = ['5GB1_FM40_T0m_TR2', '5GB1_FM40_T10m_TR3', '5GB1_FM40_T20m_TR2', '5GB1_FM40_T40m_TR1',\n",
    "           '5GB1_FM40_T60m_TR1', '5GB1_FM40_T90m_TR2', '5GB1_FM40_T150m_TR1_remake', '5GB1_FM40_T180m_TR1']\n",
    "\n",
    "    TPM_counts(df,\"start_coord\",\"end_coord\",columns)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create empty dataframe \n",
    "    gene_length = pd.DataFrame()\n",
    "    \n",
    "    #gene length in kilo base pairs as new column\n",
    "    gene_length[\"gene_length\"] = (dataframe[gene_stop]- dataframe[gene_start] + 1)/1000   \n",
    "    \n",
    "    #normalize read counts by gene length in kilo base pairs\n",
    "    RPK = dataframe.loc[:,columns].div(gene_length.gene_length, axis=0) \n",
    "    \n",
    "    #creating a series with the sums of each FM40 column / 1,000,000\n",
    "    norm_sum = RPK.sum(axis=0)/1000000 \n",
    "    norm_sum1 = pd.Series.to_frame(norm_sum)\n",
    "    norm_sum2 = norm_sum1.T\n",
    "    \n",
    "    #dividing by the the total transcript counts in each repicate\n",
    "    TPM = RPK.div(norm_sum2.ix[0]) \n",
    "    \n",
    "    dataframe.loc[:,columns] = TPM\n",
    "    \n",
    "    return dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log2 fold transfrom of the TPM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_2_transform(dataframe,\n",
    "                    first_data_column,\n",
    "                    last_data_column):\n",
    "                  \n",
    "    \"\"\"\n",
    "    log_2_transform(dataframe, \n",
    "                    first_data_column, \n",
    "                    last_data_column)\n",
    "    \n",
    "    Return a new dataframe with the range of data columns log2 transformed. \n",
    "    *all zero values are changed to 1 (yield 0 after transform)\n",
    "    *all values less than 1 are changed to 1 (yield 0 after transform)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    daraframe = dataframe object variable\n",
    "    first_data_column = first column that contains actual data (first non categorical)\n",
    "    last_data_column = last column taht contains actual data (last non categorigal column)\n",
    "\n",
    "    Run the following to execute the function for Cu transition dataset. \n",
    "\n",
    "    log_2_transform(df, \"5GB1_FM40_T0m_TR2\", \"5GB1_FM40_T180m_TR1\") \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_data = dataframe.loc[:,first_data_column:last_data_column] #isolate the data\n",
    "    \n",
    "    df_data = df_data.replace(0,1) #replace all zeros with 1s\n",
    "    \n",
    "    df_data[df_data<1] = 1 #replace all values less than 1 with 1\n",
    "    \n",
    "    df_data_log2 = df_data.apply(np.log2)\n",
    "    \n",
    "    return df_data_log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating congruency table - pearson correlation across every pair of rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def congruency_table(df, \n",
    "         data_clm_strt, \n",
    "         data_clm_stop, \n",
    "         step, \n",
    "         mask_diagonal=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    corr(df, data_clm_strt, data_clm_stop, step = len(df.columns), mask_diagonal=False)\n",
    "    \n",
    "    returns a new datafram - congruency table - a pairwise pearson correlation matrix for every row pair\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df - dataframe argument - recommended to use TPM counts for RNAseq datasets. \n",
    "    data_clm_strt = first column that contains data to be processed \n",
    "    data_clm_stop = last column that contains data to be processed\n",
    "    step = length of dataset \n",
    "    mask_diagonal = mask diagonal values which shoud come out as 1\n",
    "    \n",
    "    \n",
    "    Run the following lines to execute the function for my data\n",
    "    \n",
    "    congruency_table(df1, \"5GB1_FM40_T0m_TR2\" , \"5GB1_FM40_T180m_TR1\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.loc[:, data_clm_strt: data_clm_stop] #isolating the rows that are relavent to us. \n",
    "    df = df.T \n",
    "    \n",
    "    n = df.shape[0]\n",
    "\n",
    "    def corr_closure(df):\n",
    "        d = df.values\n",
    "        sums = d.sum(0, keepdims=True)\n",
    "        stds = d.std(0, keepdims=True)\n",
    "\n",
    "        def corr_(k=0, l=10):\n",
    "            d2 = d.T.dot(d[:, k:l])\n",
    "            sums2 = sums.T.dot(sums[:, k:l])\n",
    "            stds2 = stds.T.dot(stds[:, k:l])\n",
    "\n",
    "            return pd.DataFrame((d2 - sums2 / n) / stds2 / n,\n",
    "                                df.columns, df.columns[k:l])\n",
    "\n",
    "        return corr_\n",
    "\n",
    "    c = corr_closure(df)\n",
    "\n",
    "    step = min(step, df.shape[1])\n",
    "\n",
    "    tups = zip(range(0, n, step), range(step, n + step, step))\n",
    "\n",
    "    corr_table = pd.concat([c(*t) for t in tups], axis=1)\n",
    "\n",
    "    if mask_diagonal:\n",
    "        np.fill_diagonal(corr_table.values, np.nan)\n",
    "\n",
    "    return corr_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to tie it all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1_raw_FM40 = raw_data_cleanup(\"5G_counts.tsv\")\n",
    "\n",
    "\n",
    "columns = ['5GB1_FM40_T0m_TR2', '5GB1_FM40_T10m_TR3', '5GB1_FM40_T20m_TR2', '5GB1_FM40_T40m_TR1',\n",
    "           '5GB1_FM40_T60m_TR1', '5GB1_FM40_T90m_TR2', '5GB1_FM40_T150m_TR1_remake', '5GB1_FM40_T180m_TR1']\n",
    "\n",
    "df2_TPM = TPM_counts(df1_raw_FM40, \"start_coord\", \"end_coord\",columns)  #TPM counts\n",
    "\n",
    "df2_TPM_log2 = log_2_transform(df2_TPM, \"5GB1_FM40_T0m_TR2\",\"5GB1_FM40_T180m_TR1\") #TPM log 2 transformed \n",
    "\n",
    "\n",
    "df3_matrix = congruency_table(df2_TPM, \"5GB1_FM40_T0m_TR2\" , \"5GB1_FM40_T180m_TR1\", step = df2_TPM.shape[0])\n",
    "\n",
    "print(\"The shape of the TPM table is \", df2_TPM.shape)\n",
    "print(\"The shape of the congruency table is \", df3_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
